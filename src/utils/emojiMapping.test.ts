import { convertWeiboEmojis, addParagraphMarkers, MarkerStyle, convertWeiboHashtags, splitTextIntoChunks } from './emojiMapping';

describe('Emoji Converter', () => {
  test('converts Weibo emojis to standard emojis', () => {
    const input = 'ä»Šå¤©å¤©æ°”çœŸå¥½[å¾®ç¬‘]å¸Œæœ›æ˜å¤©ä¹Ÿæ˜¯[å“ˆå“ˆ]';
    const expected = 'ä»Šå¤©å¤©æ°”çœŸå¥½ğŸ˜Šå¸Œæœ›æ˜å¤©ä¹Ÿæ˜¯ğŸ˜„';
    expect(convertWeiboEmojis(input)).toBe(expected);
  });

  test('handles multiple emojis in a single text', () => {
    const input = 'è¿™çœŸçš„å¤ªæœ‰è¶£äº†[ç¬‘cry][ç¬‘cry][ç¬‘cry]';
    const expected = 'è¿™çœŸçš„å¤ªæœ‰è¶£äº†ğŸ˜‚ğŸ˜‚ğŸ˜‚';
    expect(convertWeiboEmojis(input)).toBe(expected);
  });

  test('handles text with no emojis', () => {
    const input = 'è¿™æ˜¯ä¸€æ®µæ²¡æœ‰è¡¨æƒ…ç¬¦å·çš„æ–‡æœ¬';
    expect(convertWeiboEmojis(input)).toBe(input);
  });
});

describe('Hashtag Converter', () => {
  test('converts Weibo hashtags from #topic# to #topic format', () => {
    const input = 'ä»Šå¤©æˆ‘å»äº†#åŒ—äº¬åŠ¨ç‰©å›­#çœ‹ç†ŠçŒ«';
    const expected = 'ä»Šå¤©æˆ‘å»äº†#åŒ—äº¬åŠ¨ç‰©å›­çœ‹ç†ŠçŒ«';
    expect(convertWeiboHashtags(input)).toBe(expected);
  });

  test('handles multiple hashtags in a single text', () => {
    const input = 'æˆ‘å–œæ¬¢#æ—…è¡Œ#å’Œ#ç¾é£Ÿ#';
    const expected = 'æˆ‘å–œæ¬¢#æ—…è¡Œå’Œ#ç¾é£Ÿ';
    expect(convertWeiboHashtags(input)).toBe(expected);
  });

  test('handles text with no hashtags', () => {
    const input = 'è¿™æ˜¯ä¸€æ®µæ²¡æœ‰æ ‡ç­¾çš„æ–‡æœ¬';
    expect(convertWeiboHashtags(input)).toBe(input);
  });

  test('handles complex hashtag cases', () => {
    const input = '#æ—…è¡Œ##ç¾é£Ÿ##å¥èº«#';
    const expected = '#æ—…è¡Œ#ç¾é£Ÿ#å¥èº«';
    expect(convertWeiboHashtags(input)).toBe(expected);
  });
});

describe('Paragraph Marker', () => {
  test('adds default paragraph markers to the beginning of each paragraph', () => {
    const input = 'ç¬¬ä¸€æ®µ\nç¬¬äºŒæ®µ\nç¬¬ä¸‰æ®µ';
    const expected = 'â¤ ç¬¬ä¸€æ®µ\nâ¤ ç¬¬äºŒæ®µ\nâ¤ ç¬¬ä¸‰æ®µ';
    expect(addParagraphMarkers(input)).toBe(expected);
  });

  test('adds custom paragraph markers to the beginning of each paragraph', () => {
    const input = 'ç¬¬ä¸€æ®µ\nç¬¬äºŒæ®µ\nç¬¬ä¸‰æ®µ';
    const markerStyles: MarkerStyle[] = ['ğŸ”¹', 'ğŸŒ¸', 'âœ¨', 'ğŸ’ '];
    
    markerStyles.forEach(style => {
      const expected = `${style} ç¬¬ä¸€æ®µ\n${style} ç¬¬äºŒæ®µ\n${style} ç¬¬ä¸‰æ®µ`;
      expect(addParagraphMarkers(input, style)).toBe(expected);
    });
  });

  test('handles empty lines', () => {
    const input = 'ç¬¬ä¸€æ®µ\n\nç¬¬äºŒæ®µ';
    const expected = 'â¤ ç¬¬ä¸€æ®µ\n\nâ¤ ç¬¬äºŒæ®µ';
    expect(addParagraphMarkers(input)).toBe(expected);
  });

  test('handles text with no line breaks', () => {
    const input = 'è¿™æ˜¯ä¸€æ®µæ²¡æœ‰æ¢è¡Œçš„æ–‡æœ¬';
    const expected = 'â¤ è¿™æ˜¯ä¸€æ®µæ²¡æœ‰æ¢è¡Œçš„æ–‡æœ¬';
    expect(addParagraphMarkers(input)).toBe(expected);
  });
});

describe('Text Chunking', () => {
  test('should not split text that is under the limit', () => {
    const input = 'è¿™æ˜¯ä¸€æ®µä¸è¶…è¿‡å­—æ•°é™åˆ¶çš„æ–‡æœ¬';
    const result = splitTextIntoChunks(input, 900);
    expect(result.length).toBe(1);
    expect(result[0]).toBe(input);
  });

  test('should split text at paragraph boundaries when possible', () => {
    const paragraph1 = 'ç¬¬ä¸€æ®µè½ï¼šè¿™æ˜¯ç¬¬ä¸€æ®µå†…å®¹ã€‚'.repeat(20); // ~200 chars
    const paragraph2 = 'ç¬¬äºŒæ®µè½ï¼šè¿™æ˜¯ç¬¬äºŒæ®µå†…å®¹ã€‚'.repeat(20); // ~200 chars
    const paragraph3 = 'ç¬¬ä¸‰æ®µè½ï¼šè¿™æ˜¯ç¬¬ä¸‰æ®µå†…å®¹ã€‚'.repeat(20); // ~200 chars
    const paragraph4 = 'ç¬¬å››æ®µè½ï¼šè¿™æ˜¯ç¬¬å››æ®µå†…å®¹ã€‚'.repeat(20); // ~200 chars
    const paragraph5 = 'ç¬¬äº”æ®µè½ï¼šè¿™æ˜¯ç¬¬äº”æ®µå†…å®¹ã€‚'.repeat(20); // ~200 chars
    
    const input = `${paragraph1}\n\n${paragraph2}\n\n${paragraph3}\n\n${paragraph4}\n\n${paragraph5}`;
    
    const result = splitTextIntoChunks(input, 500);
    
    expect(result.length).toBe(5);
    expect(result[0]).toContain('ç¬¬ä¸€æ®µè½');
    expect(result[1]).toContain('ç¬¬äºŒæ®µè½');
  });

  test('should split at sentence boundaries if paragraph splits are not available', () => {
    const longSentence1 = 'è¿™æ˜¯ç¬¬ä¸€ä¸ªå¥å­ï¼Œå®ƒæœ‰ä¸€äº›å†…å®¹ã€‚';
    const longSentence2 = 'è¿™æ˜¯ç¬¬äºŒä¸ªå¥å­ï¼Œå®ƒä¹Ÿæœ‰ä¸€äº›å†…å®¹ï¼';
    const longSentence3 = 'è¿™æ˜¯ç¬¬ä¸‰ä¸ªå¥å­ï¼Œå®ƒåŒ…å«äº†æ›´å¤šçš„å†…å®¹ï¼Ÿ';
    const longSentence4 = 'è¿™æ˜¯ç¬¬å››ä¸ªå¥å­ï¼Œå®ƒåŒ…å«äº†ä¸€äº›ç¤ºä¾‹æ–‡æœ¬ã€‚';
    
    // Repeat sentences to make it long enough to force splitting
    const input = (longSentence1 + longSentence2 + longSentence3 + longSentence4).repeat(10);
    
    const result = splitTextIntoChunks(input, 300);
    
    expect(result.length).toBeGreaterThan(1);
    
    // Each chunk (except maybe the last) should end with a sentence terminator
    for (let i = 0; i < result.length - 1; i++) {
      expect(result[i]).toMatch(/[.!?]$/);
    }
  });

  test('should handle very long text with multiple chunks', () => {
    const longText = 'è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ã€‚'.repeat(300); // ~1200 chars
    const result = splitTextIntoChunks(longText, 300);
    
    expect(result.length).toBeGreaterThan(3);
    
    // Make sure we never exceed the max chunk size
    result.forEach(chunk => {
      expect(chunk.length).toBeLessThanOrEqual(300);
    });
    
    // Check that all content is preserved
    const combinedText = result.join('');
    const normalizedInput = longText.replace(/\s+/g, '');
    const normalizedOutput = combinedText.replace(/\s+/g, '');
    
    expect(normalizedOutput).toEqual(normalizedInput);
  });

  test('should handle small character limits like Twitter (140 chars)', () => {
    const tweetText = 'Twitter only allows 140 characters per tweet, so this text needs to be split into multiple parts to fit within that constraint. This is a test of that functionality.';
    const result = splitTextIntoChunks(tweetText, 140);
    
    expect(result.length).toBeGreaterThan(1);
    
    // Check all chunks are under the limit
    result.forEach(chunk => {
      expect(chunk.length).toBeLessThanOrEqual(140);
    });
    
    // Check content preservation
    const combined = result.join('');
    expect(combined.replace(/\s+/g, '')).toEqual(tweetText.replace(/\s+/g, ''));
  });

  test('should split Chinese characters properly with various limits', () => {
    const chineseText = 'è¿™æ˜¯ä¸€æ®µä¸­æ–‡æ–‡æœ¬ï¼Œæˆ‘ä»¬éœ€è¦æµ‹è¯•å®ƒåœ¨ä¸åŒå­—ç¬¦é™åˆ¶ä¸‹çš„åˆ†å‰²æ•ˆæœã€‚å¾®åšã€å°çº¢ä¹¦å’ŒTwitteréƒ½æœ‰è‡ªå·±çš„å­—ç¬¦é™åˆ¶ã€‚æˆ‘ä»¬éœ€è¦ç¡®ä¿æ–‡æœ¬èƒ½å¤Ÿåœ¨åˆé€‚çš„ä½ç½®åˆ†å‰²ï¼Œä¿æŒè¯­ä¹‰çš„å®Œæ•´æ€§ã€‚';
    
    // Test with Twitter limit
    const twitterChunks = splitTextIntoChunks(chineseText, 140);
    expect(twitterChunks[0].length).toBeLessThanOrEqual(140);
    
    // Test with Facebook limit
    const fbChunks = splitTextIntoChunks(chineseText, 500);
    expect(fbChunks[0].length).toBeLessThanOrEqual(500);
    
    // Verify content remains intact
    const combinedTwitter = twitterChunks.join('');
    const combinedFb = fbChunks.join('');
    expect(combinedTwitter).toEqual(chineseText);
    expect(combinedFb).toEqual(chineseText);
  });
}); 